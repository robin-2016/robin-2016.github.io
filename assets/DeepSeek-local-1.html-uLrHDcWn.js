import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as e,o as l}from"./app-DcZA98cq.js";const n={};function t(h,i){return l(),a("div",null,i[0]||(i[0]=[e(`<h1 id="目前我见到的全网硬件成本最低运行deepseek-r1-671b满血版完整指南-翻译" tabindex="-1"><a class="header-anchor" href="#目前我见到的全网硬件成本最低运行deepseek-r1-671b满血版完整指南-翻译"><span>目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译）</span></a></h1><h2 id="deepseek-ai本地推理设备搭建" tabindex="-1"><a class="header-anchor" href="#deepseek-ai本地推理设备搭建"><span>Deepseek AI本地推理设备搭建</span></a></h2><p>好消息：基于我们一直使用的AMD EPYC Rome基准系统获得了稳定性能表现😁 这套初始配置依然出色！设备拥有者现在可以在Q4 671b完整模型上获得4.25-3.5 TPS（每秒令牌数）。完整版16K以上上下文窗口的模型体验远胜精简版，值得投入。纯CPU运行时可同时运行视觉模型等小型模型。</p><p>2024/02/01补充参数：</p><p>空载功耗：60W（未接GPU）</p><p>满载功耗：260W</p><p>当前内存速度：2400（3200可能有性能提升）</p><h3 id="本地ai-cpu计算硬件" tabindex="-1"><a class="header-anchor" href="#本地ai-cpu计算硬件"><span>本地AI CPU计算硬件</span></a></h3><p>若已按我之前的3090四卡指南装机，恭喜你！7702依然强劲。建议升级同价位性能更强的CPU，但本文结果基于7702。MZ32-AR0主板通过16个DDR4 3200内存插槽可轻松实现512GB-1TB内存扩容（注意：<strong>不能混用LRDIMM和RDIMM内存！</strong>）</p><h3 id="本地ai设备组件" tabindex="-1"><a class="header-anchor" href="#本地ai设备组件"><span>本地AI设备组件</span></a></h3><ul><li>机架框架 $55</li><li>MZ32-AR0主板 $500</li><li>420mm水冷 Corsair h170i elite capellix xt $170</li><li>EPYC水冷支架</li><li>AMD EPYC 7702（64核）$650 / 7V13 $599 / 7C13 $735</li><li>512GB 2400 ECC内存 $400</li><li>1TB NVMe 三星980 Pro $75</li><li>850W电源 $80（纯CPU推理够用，需接GPU建议1600W）</li></ul><p>(2025年1月29日报价)</p><p><strong>总成本约$2000</strong>（使用512GB 2400内存和7702时）。建议优先升级7C13/7V13 CPU，其次768GB内存，最后考虑3200内存。</p><h3 id="服务器架设要点" tabindex="-1"><a class="header-anchor" href="#服务器架设要点"><span>服务器架设要点</span></a></h3><ol><li>内存散热：用4个80mm风扇组成风墙直吹内存条</li><li>主板升级：MZ32-AR0 V3版主板直接支持Milan架构CPU</li><li>BIOS设置：NPS=1、SMT关闭、cTDP=200、BoostFmax=3400等</li></ol><h2 id="本地ai软件部署" tabindex="-1"><a class="header-anchor" href="#本地ai软件部署"><span>本地AI软件部署</span></a></h2><h3 id="ubuntu-24基础安装" tabindex="-1"><a class="header-anchor" href="#ubuntu-24基础安装"><span>Ubuntu 24基础安装</span></a></h3><ol><li>通过BMC管理界面挂载Ubuntu 24.04 ISO</li><li>BIOS设置：UEFI/Legacy模式、性能优先配置</li><li>网络配置：使用netplan设置静态IP</li></ol><h3 id="ollama安装步骤" tabindex="-1"><a class="header-anchor" href="#ollama安装步骤"><span>Ollama安装步骤</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 安装基础工具</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -y</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> htop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> glances</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nano</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 下载安装Ollama</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">curl</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -L</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">https://ollama.com/download/ollama-linux-amd64.tg</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">z&gt; </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">-o</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ollama.tgz</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> tar</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -C</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /usr</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -xzf</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ollama.tgz</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> useradd</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /bin/</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">false</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -U</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -d</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /usr/share/ollama</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ollama</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 服务配置</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nano</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /etc/systemd/system/ollama.service</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 添加环境变量：</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">Environment</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">OLLAMA_NUM_PARALLEL</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">62</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">Environment</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">OLLAMA_KEEP_ALIVE</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">3h</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="openwebui部署" tabindex="-1"><a class="header-anchor" href="#openwebui部署"><span>OpenWEBUI部署</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 安装Docker</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt-get</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> docker-ce</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 部署Dockge管理界面</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> mkdir</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /opt/stacks</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /opt/dockge</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /opt/dockge</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> curl</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -O</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">https://raw.githubusercontent.com/louislam/dockge/master/compose.yam</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">l&gt;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> compose</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> up</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -d</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># OpenWEBUI配置</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">version:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;3.3&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">services:</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">  open-webui:</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ports:</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">      -</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 7000:8080</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    image:</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ghcr.io/open-webui/open-webui:latest</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="性能优化建议" tabindex="-1"><a class="header-anchor" href="#性能优化建议"><span>性能优化建议</span></a></h2><ol><li>上下文长度设置为16384（16K）</li><li>线程数设为62（保留2个核心）</li><li>启用mlock防止内存分页</li><li>保持连接存活时间3小时</li></ol><p>完整配置后可实现3.5-4.25 TPS的推理速度。该方案虽需技术调试，但能获得完整版模型的优质体验。后续将推出llama.cpp等框架的优化指南。</p><p>本文翻译自<a href="https://digitalspaceport.com/how-to-run-deepseek-r1-671b-fully-locally-on-2000-epyc-rig/?continueFlag=d7f6384b375643a120a8439ff012b5ac" target="_blank" rel="noopener noreferrer">https://digitalspaceport.com/how-to-run-deepseek-r1-671b-fully-locally-on-2000-epyc-rig/?continueFlag=d7f6384b375643a120a8439ff012b5ac</a>，点击原文查看</p>`,26)]))}const r=s(n,[["render",t],["__file","DeepSeek-local-1.html.vue"]]),d=JSON.parse('{"path":"/posts/DeepSeek-local-1.html","title":"目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译）","lang":"zh-CN","frontmatter":{"icon":"pen-to-square","date":"2025-02-08T00:00:00.000Z","star":true,"category":["AI"],"tag":["DeepSeek","Local-AI"],"description":"目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译） Deepseek AI本地推理设备搭建 好消息：基于我们一直使用的AMD EPYC Rome基准系统获得了稳定性能表现😁 这套初始配置依然出色！设备拥有者现在可以在Q4 671b完整模型上获得4.25-3.5 TPS（每秒令牌数）。完整版16K以上上下文窗口的模型...","head":[["meta",{"property":"og:url","content":"https://robin-2016.github.io/posts/DeepSeek-local-1.html"}],["meta",{"property":"og:site_name","content":"RobinDevNotes"}],["meta",{"property":"og:title","content":"目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译）"}],["meta",{"property":"og:description","content":"目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译） Deepseek AI本地推理设备搭建 好消息：基于我们一直使用的AMD EPYC Rome基准系统获得了稳定性能表现😁 这套初始配置依然出色！设备拥有者现在可以在Q4 671b完整模型上获得4.25-3.5 TPS（每秒令牌数）。完整版16K以上上下文窗口的模型..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:tag","content":"DeepSeek"}],["meta",{"property":"article:tag","content":"Local-AI"}],["meta",{"property":"article:published_time","content":"2025-02-08T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"目前我见到的全网硬件成本最低运行DeepSeek R1 671b满血版完整指南（翻译）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-02-08T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Robin\\",\\"url\\":\\"https://robin-2016.github.io\\"}]}"]]},"headers":[{"level":2,"title":"Deepseek AI本地推理设备搭建","slug":"deepseek-ai本地推理设备搭建","link":"#deepseek-ai本地推理设备搭建","children":[{"level":3,"title":"本地AI CPU计算硬件","slug":"本地ai-cpu计算硬件","link":"#本地ai-cpu计算硬件","children":[]},{"level":3,"title":"本地AI设备组件","slug":"本地ai设备组件","link":"#本地ai设备组件","children":[]},{"level":3,"title":"服务器架设要点","slug":"服务器架设要点","link":"#服务器架设要点","children":[]}]},{"level":2,"title":"本地AI软件部署","slug":"本地ai软件部署","link":"#本地ai软件部署","children":[{"level":3,"title":"Ubuntu 24基础安装","slug":"ubuntu-24基础安装","link":"#ubuntu-24基础安装","children":[]},{"level":3,"title":"Ollama安装步骤","slug":"ollama安装步骤","link":"#ollama安装步骤","children":[]},{"level":3,"title":"OpenWEBUI部署","slug":"openwebui部署","link":"#openwebui部署","children":[]}]},{"level":2,"title":"性能优化建议","slug":"性能优化建议","link":"#性能优化建议","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":2.58,"words":775},"filePathRelative":"posts/DeepSeek-local-1.md","localizedDate":"2025年2月8日","excerpt":"\\n<h2>Deepseek AI本地推理设备搭建</h2>\\n<p>好消息：基于我们一直使用的AMD EPYC Rome基准系统获得了稳定性能表现😁 这套初始配置依然出色！设备拥有者现在可以在Q4 671b完整模型上获得4.25-3.5 TPS（每秒令牌数）。完整版16K以上上下文窗口的模型体验远胜精简版，值得投入。纯CPU运行时可同时运行视觉模型等小型模型。</p>\\n<p>2024/02/01补充参数：</p>\\n<p>空载功耗：60W（未接GPU）</p>\\n<p>满载功耗：260W</p>\\n<p>当前内存速度：2400（3200可能有性能提升）</p>\\n<h3>本地AI CPU计算硬件</h3>","autoDesc":true}');export{r as comp,d as data};
